{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbdd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f002d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  male  Q  S\n",
       "0         0       3  22.0      1      0   7.2500     1  0  1\n",
       "1         1       1  38.0      1      0  71.2833     0  0  0\n",
       "2         1       3  26.0      0      0   7.9250     0  0  1\n",
       "3         1       1  35.0      1      0  53.1000     0  0  1\n",
       "4         0       3  35.0      0      0   8.0500     1  0  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the raw dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# remove columns we don't need\n",
    "titanic = titanic.drop(['class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone'], axis=1)\n",
    "\n",
    "# take care of missing age entries by filling them in with the median age\n",
    "titanic['age'].fillna(titanic.groupby('pclass')['age'].transform(\"median\"), inplace=True)\n",
    "\n",
    "# drop rows with missing elements\n",
    "titanic.dropna(inplace=True)\n",
    "\n",
    "# Convert categorical variable into dummy/indicator variables (1's and 0's, easier to work with)\n",
    "new_sex = pd.get_dummies(titanic['sex'], drop_first=True)\n",
    "\n",
    "# Convert categorical variable into dummy/indicator variables (1's and 0's, easier to work with)\n",
    "new_embarked = pd.get_dummies(titanic['embarked'], drop_first=True)\n",
    "\n",
    "# add dummy variables (columns) to dataframe\n",
    "titanic = pd.concat([titanic, new_sex, new_embarked], axis=1)\n",
    "\n",
    "# drop original categorical variables (columns)\n",
    "titanic.drop(['sex', 'embarked'],axis=1, inplace=True)\n",
    "\n",
    "# show first 5 rows as a demo\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd84dadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((622, 8), (622,), (267, 8), (267,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# library to split dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X is all possible features/independent variables\n",
    "X = titanic.drop('survived', axis=1)\n",
    "# Y is what we are modeling\n",
    "Y = titanic['survived']\n",
    "\n",
    "# split the data with 30% of rows going to the training set and a state seed of 1000 for consistency\n",
    "trainX, testX, trainY, testY = train_test_split(X,Y,test_size=0.3, random_state = 1000)\n",
    "\n",
    "# print the shape of the split dataframes (rows, columns)\n",
    "trainX.shape, trainY.shape, testX.shape, testY.shape\n",
    "\n",
    "# we started with 889 observations - 622 are for training and 267 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39aa81dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timst\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# import library for logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# the C parameter is for avoiding overfitting using penalty terms\n",
    "# this is not needed for this project, so a very large value is used to 'disable' it\n",
    "# build the model\n",
    "logreg = LogisticRegression(C=1e10)\n",
    "\n",
    "# fit the model with data\n",
    "fit = logreg.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6548a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optimal cutoff value is: 0.61 and the accuracy with this value is: 0.8344051446945338\n"
     ]
    }
   ],
   "source": [
    "#Question 1: Finding the optimal value\n",
    "\n",
    "accuracyTemp = 0\n",
    "maxAccuracy = 0\n",
    "maxCutoff = 0\n",
    "    \n",
    "# for each possible cutoff value between 0 and 1 by increments of 0.01\n",
    "for i in range(1, 100, 1):\n",
    "    cutoff = i/100\n",
    "    # make array of predictions for each row, either a 0 for death or 1 for survival\n",
    "    # the [:,1] returns only prediction of survival which is compared to cutoff value to determine binary value\n",
    "    prob_of_1 = (logreg.predict_proba(trainX)[:,1] >= cutoff).astype(bool)\n",
    "    # find accuracy by dividing the number of correct predictions by the total number of records\n",
    "    accuracyTemp = np.sum(trainY == prob_of_1)/622\n",
    "    # if highest accuracy so far, replace accuracy and cutoff value in optimal\n",
    "    if (accuracyTemp >= maxAccuracy):\n",
    "        maxCutoff = cutoff\n",
    "        maxAccuracy = accuracyTemp\n",
    "        \n",
    "#optimal cutoff\n",
    "print(\"the optimal cutoff value is: \" + str(maxCutoff) + \" and the accuracy with this value is: \" + str(maxAccuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d80c1c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default accuracy with a cutoff value of 0.5:  0.7790262172284644\n",
      "Accuracy for cutoff of 0.61:  0.7902621722846442 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 2: use optimal cutoff value to see how the model performs on the test data\n",
    "\n",
    "# default cutoff accuracy\n",
    "print(\"Default accuracy with a cutoff value of 0.5: \", fit.score(testX, testY))\n",
    "\n",
    "# custom cutoff accuracy\n",
    "prob_of_1 = (logreg.predict_proba(testX)[:,1] >= 0.61).astype(bool)\n",
    "print(\"Accuracy for cutoff of 0.61: \", np.sum(testY == prob_of_1)/267, \"\\n\")\n",
    "\n",
    "# note the slightly improved accuracy when using the custom cutoff\n",
    "# there is also a decline of 4% from training to testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e24a14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[144,  18],\n",
       "       [ 38,  67]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom cutoff confusion matrix\n",
    "metrics.confusion_matrix(testY, prob_of_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1584068b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[138,  24],\n",
       "       [ 35,  70]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default cutoff confusion matrix\n",
    "metrics.confusion_matrix(testY, fit.predict(testX))\n",
    "\n",
    "# the default cutoff has more false positives and less false negatives"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
